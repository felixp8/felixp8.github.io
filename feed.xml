<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://felixp8.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://felixp8.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2023-12-02T23:03:34+00:00</updated><id>https://felixp8.github.io/feed.xml</id><title type="html">Felix Pei</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">approximation of discrete delays with continuous-time dynamics</title><link href="https://felixp8.github.io/blog/2023/cont-delay/" rel="alternate" type="text/html" title="approximation of discrete delays with continuous-time dynamics"/><published>2023-11-27T21:01:00+00:00</published><updated>2023-11-27T21:01:00+00:00</updated><id>https://felixp8.github.io/blog/2023/cont-delay</id><content type="html" xml:base="https://felixp8.github.io/blog/2023/cont-delay/"><![CDATA[<p>In discrete-time dynamical systems, it’s easy to create a state variable that is a time-delayed copy of another. For example, if we have a linear system</p> \[\begin{bmatrix} x_1(t + 1) \\ x_2(t + 1) \\ x_3(t + 1) \end{bmatrix} = A \cdot \begin{bmatrix} x_1(t) \\ x_2(t) \\ x_3(t) \end{bmatrix}\] <p>and we want \(x_3\) to be equal to \(x_1\), but delayed by one timestep, we can design A as</p> \[A = \begin{bmatrix} a_{11} &amp; a_{12} &amp; a_{13} \\ a_{21} &amp; a_{22} &amp; a_{23} \\ 1 &amp; 0 &amp; 0 \end{bmatrix}\] <p>so that \(x_3(t + 1) = x_1(t)\). Of course, we can only ever create delays of exactly one timestep, and to achieve greater delays we’d need to chain multiple variables each delayed by a timestep. More generally, in discrete-time systems, state variables can only affect each other with a one timestep delay.</p> <p>In continuous-time systems, state variables affect each other instantaneously. It is therefore not obvious how to recreate this sort of time-delayed relationship between variables, though this occurs often in real-world systems, e.g. in interacting brain regions. This problem has been extensively studied in a variety of fields, but because I am too lazy to look into it, I just messed around a bit myself and found a solution that is probably pretty useless.</p> <h3 id="problem-statement">Problem statement</h3> <p>Let me try to state the problem a little more clearly. We have a continuous-time dynamical system</p> \[\dot{x} = f(x,u)\] <p>where \(x \in \mathbb{R}^{N}\). We want to make some sort of coupled dynamical system with a new state variable \(y\) so that \(y(t) = x_{i}(t - \tau)\) for some index \(i \in [1, N]\) and some delay \(\tau &gt; 0\). This means that we want</p> \[\dot{y}(t) = \dot{x}_{i}(t - \tau).\] <p>In theory, we could maintain an entire delayed copy of \(x\) and compute \(\dot{x}_{i}(t - \tau)\) just from \(f\), but this is generally impractical because</p> <ol> <li>we’d need to also store all external inputs \(u(t)\) for \([t - \tau, t]\)</li> <li>we’d need to initialize this copied system exactly to \(x(t - \tau)\)</li> </ol> <p>Instead, if we could estimate \(\dot{x}_{i}(t - \tau)\) purely from observables at time \(t\) and allow for some margin of error in initializing \(y\), that would be potentially less accurate but more useful.</p> <h3 id="prior-work-finite-differences">Prior work: Finite differences</h3> <p>Though I didn’t do much research on prior work, I did look at the first search result<sup id="fnref:fn1" role="doc-noteref"><a href="#fn:fn1" class="footnote" rel="footnote">1</a></sup>. The method proposed there is very simple: approximate</p> \[\dot{x}_{i}(t - \tau) \approx \dot{y}(t) = \frac{x_{i}(t) - y(t)}{\tau}.\] <p>If \(y(t) = x_{i}(t - \tau)\) exactly, then the estimate is equal to</p> \[\frac{x_{i}(t) - x_{i}(t - \tau)}{\tau},\] <p>which converges to \(\dot{x}_{i}(t - \tau)\) as \(\tau \to 0\).</p> <p>As you can imagine, this becomes less accurate for larger \(\tau\), so instead of going straight for \(\tau\), you can break up the delay into many smaller intervals where each derivative estimate is likely to be more accurate. The resulting system would look something like this:</p> \[\dot{x} = f(x,u)\] \[\dot{y}_1 = (x_i - y_1) / \Delta t\] \[\dot{y}_2 = (y_1 - y_2) / \Delta t\] \[...\] \[\dot{y}_m = (y_{m-1} - y_m) / \Delta t\] <p>which gives a total delay of \(m \cdot \Delta t\) for \(y_m\). If it helps to see it in matrix form, the above could also be written like this:</p> \[\begin{bmatrix} \dot{x} \\ \dot{y}_1 \\ \\ \vdots \\ \\ \dot{y}_m \end{bmatrix} = \begin{bmatrix} f_{lin} &amp; 0 &amp; &amp; \dots &amp; &amp; 0 \\ \frac{1}{\Delta t} &amp; -\frac{1}{\Delta t} &amp; 0 &amp; &amp; \dots &amp; \\ 0 &amp; \frac{1}{\Delta t} &amp; -\frac{1}{\Delta t} &amp; &amp; \dots &amp; \\ &amp; &amp; \ddots &amp; \ddots &amp; &amp; \\ &amp; &amp; &amp; \ddots &amp; \ddots &amp; \\ 0 &amp; &amp; \dots &amp; &amp; \frac{1}{\Delta t} &amp; -\frac{1}{\Delta t} \end{bmatrix} \begin{bmatrix} x \\ y_1 \\ \\ \vdots \\ \\ y_m \end{bmatrix} + \begin{bmatrix} 1 \\ 0 \\ \\ \vdots \\ \\ 0 \end{bmatrix} f_{nonlin}(x,u)\] <p>where \(f_{lin}\) is whatever component of \(f\) can be represented as a linear function of \(x\) and \(f_{nonlin}\) is everything else. (My weird notation of \(f_{lin}\) and \(f_{nonlin}\) is irrelevant though - the main idea is the rest of the matrix!)</p> <p>There are a few nice things about this method:</p> <ol> <li>The dynamics of the delayed variables do not depend explicitly on the inputs at all. Instead, they account for the effect of the inputs only by looking at \(x_{i}\) directly.</li> <li>The system sort of self-corrects for inaccurate initializations. If \(\Delta t\) is small enough, we can assume that all gradient estimates are accurate when \(y\) values are accurate. Then, for example, if \(y\) is initialized too small, the gradient estimate from the finite difference will be bigger than the true gradient, which compensates for the initialization error.</li> </ol> <p>The method can be extended/improved with central differences or unevenly-spaced \(y\) points, which may give better accuracy<sup id="fnref:fn1:1" role="doc-noteref"><a href="#fn:fn1" class="footnote" rel="footnote">1</a></sup><sup id="fnref:fn2" role="doc-noteref"><a href="#fn:fn2" class="footnote" rel="footnote">2</a></sup>.</p> <p>Lastly, notice that if our integration timestep is also \(\Delta t\), then \(\Delta t \cdot \pm 1 / \Delta t = \pm 1\), and we have recreated the original discrete system. The -1’s on the diagonal would be canceled out by adding the identity matrix, since discrete systems output the next state, not the difference between the current and next state.</p> <h3 id="finding-an-alternate-solution-by-inverting-the-continuous-to-discrete-transformation">Finding an alternate solution by inverting the continuous-to-discrete transformation</h3> <p>Instead of doing something principled like the paper above, I decided to just try to directly convert a discrete-time linear system with delays into a continuous-time one. Thanks to Stack Exchange, I found that the bilinear transform is easily invertible<sup id="fnref:fn3" role="doc-noteref"><a href="#fn:fn3" class="footnote" rel="footnote">3</a></sup>. For some background, the bilinear transform is essentially a trapezoidal approximation of a continuous-time linear system.</p> <p>Taking a discrete-time linear system with a delay, like the one shown in the very first section, we can apply the inverse bilinear transform to get a continuous-time system that should display the same behavior. Though I did not expect it to, it worked:</p> <p>[insert image here]</p> <p>Doing this a few times, there was a clear pattern to the resulting continuous-time systems. The dynamics of the delayed variable were always given by</p> \[\dot{y}(t) = -\dot{x}_{i}(t) + \frac{2}{\tau}(x_{i}(t) - y(t)).\] <p>This equation did not immediately make sense to me, but it’s actually quite straightforward if we rearrange it.</p> \[\dot{y}(t) + \dot{x}_{i}(t) = \frac{2}{\tau}(x_{i}(t) - y(t))\] \[\frac{\dot{y}(t) + \dot{x}_{i}(t)}{2} = \frac{x_{i}(t) - y(t)}{\tau}\] <p>If we assume the ideal of \(y(t) = x_{i}(t - \tau)\), we get</p> \[\frac{\dot{x}_{i}(t - \tau) + \dot{x}_{i}(t)}{2} = \frac{x_{i}(t) - x_{i}(t - \tau)}{\tau}.\] <p>Basically, the assumption of this solution is that the average slope between \(x_{i}(t - \tau)\) and \(x_{i}(t)\) (aka the right-hand side of the equation) is exactly in the middle of the slope at the left edge (aka \(\dot{x}_{i}(t - \tau)\)) and the slope at the right edge (aka \(\dot{x}(t - \tau)\)). This would be true of the second derivative is constant.</p> <p>The good thing about this approximation is that it retains all the benefits of the finite difference method, relying only on current observables and compensating for inaccurate initializations, while taking into account the additional information we know about \(\dot{x}_{i}(t)\) that was ignored by the finite difference method. Of course, this method also becomes more inaccurate as \(\tau\) grows, so the same partitioning of the delay used with the finite differences can still be used here, regardless of whether \(f\) is linear or non-linear.</p> <h3 id="generalizing-the-alternate-solution-with-taylor-expansions">Generalizing the alternate solution with Taylor expansions</h3> <p>TODO</p> <h3 id="references">References</h3> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:fn1" role="doc-endnote"> <p>Sun, Jian-Qiao. A method of continuous time approximation of delayed dynamical systems. In <em>Communications in Nonlinear Science and Numerical Simulation</em>, 2009. <a href="https://www.sciencedirect.com/science/article/pii/S1007570408000610">URL</a> <a href="#fnref:fn1" class="reversefootnote" role="doc-backlink">&#8617;</a> <a href="#fnref:fn1:1" class="reversefootnote" role="doc-backlink">&#8617;<sup>2</sup></a></p> </li> <li id="fn:fn2" role="doc-endnote"> <p>Butcher, Eric A. and Bobrenkov, Oleg A. On the Chebyshev spectral continuous time approximation for constant and periodic delay differential equations. In <em>Communications in Nonlinear Science and Numerical Simulation</em>, 2011. <a href="https://www.sciencedirect.com/science/article/pii/S1007570410003539">URL</a> <a href="#fnref:fn2" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:fn3" role="doc-endnote"> <p>van der Veen, Kwin. discrete-time to continuous-time state space. On <em>Mathematics Stack Exchange</em>, 2020. <a href="https://math.stackexchange.com/q/3820405">URL</a> <a href="#fnref:fn3" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name></name></author><category term="dynamical-systems"/><category term="math"/><category term="code"/><summary type="html"><![CDATA[some pointless and basic math noodling]]></summary></entry></feed>